{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d7fa8b5-f8c9-4300-b0a9-3f34b0281002",
   "metadata": {},
   "source": [
    "### CLASSIFYING ENZYMES TO FUNCTIONAL CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b1a4ab-e8c3-493d-8113-b83a8f801e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS - PART 1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be155b13-3f9e-4e25-bfdc-9d4c636d7ab0",
   "metadata": {},
   "source": [
    " * AAC - amino acid composition (frequency of each AA in a sequence) --> N x 20\n",
    " * CTD - conjoined triad descriptors () --> N x 343\n",
    " * NGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec73ff-e157-475e-a8fd-97eea70a763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA FOR SVM, kNN and RF\n",
    "aac = pd.read_csv('../dataset/aac.csv', index_col=0)\n",
    "ctd = pd.read_csv('../dataset/ctd.csv', index_col=0)\n",
    "data = pd.read_csv('../dataset/ngram.csv', index_col=0)\n",
    "data = data.join(ctd[ctd.columns[0:-1]])\n",
    "data = data.join(aac[aac.columns[0:-1]])\n",
    "y = data['class']\n",
    "data = data[data.columns[0:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8666610d-8363-429a-8bd9-22bb201a8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "mean = data.mean()\n",
    "std = data.std()\n",
    "data = (data-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec277db-16d8-4071-89a7-4127f6a53c3a",
   "metadata": {},
   "source": [
    "#### Majority Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68dc215a-1f71-4e38-b976-15f26b9f279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MAJORITY CLASSIFIER\n",
    "class Majority_class:\n",
    "    def __init__(self):\n",
    "        self.major = None\n",
    "\n",
    "    def fit(self, y):\n",
    "        self.major = y.mode()\n",
    "        return self\n",
    "        \n",
    "    def predict(self, x):\n",
    "        if self.major is not None:\n",
    "            return np.full(len(x), self.major)\n",
    "        print('Train classifier first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0de2f7f-0b3d-46fa-ab91-f24f8999bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATE MAJORITY CLASSIFIER\n",
    "results_major = []\n",
    "i = 0\n",
    "j = 2400\n",
    "while j <= y.size:\n",
    "    test_idx = np.zeros(y.size, dtype=bool)\n",
    "    test_idx[i:j] = True\n",
    "    test = y[test_idx]\n",
    "    train = y[np.invert(test_idx)]\n",
    "    major = Majority_class()\n",
    "    major = major.fit(train)\n",
    "    results_major.append(np.mean(major.predict(test) == y[test_idx].to_numpy()))\n",
    "    i = j\n",
    "    j += 2400\n",
    "    if j < y.size and y.size - j < 245:\n",
    "        j = y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b52dad98-163b-49ab-87bc-02e2011bc137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority classifier has 33.9 % accuracy with 3.674 % error\n",
      "(estimated with 10 fold cross validation)\n"
     ]
    }
   ],
   "source": [
    "acc_major = np.round(np.mean(results_major) * 100, decimals=3)\n",
    "err_major = np.round(np.std(results_major) * 100, decimals=3)\n",
    "print(\"Majority classifier has\", acc_major, \"% accuracy with\", err_major, \"% error\\n(estimated with\", len(results_major), \"fold cross validation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1f04f-be74-4124-b754-dcab22a32a11",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e94417d7-70a1-47a9-90ce-217a0b10f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC()\n",
    "results_svm = cross_val_score(clf_svm, data, y, cv=len(results_major))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef691fdd-ddde-4dba-bffb-71d3c67c3e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM has 82.359 % accuracy with 0.971 % error\n",
      "(estimated with 10 fold cross validation)\n"
     ]
    }
   ],
   "source": [
    "acc_svm = np.round(np.mean(results_svm) * 100, decimals=3)\n",
    "err_svm = np.round(np.std(results_svm) * 100, decimals=3)\n",
    "print(\"SVM has\", acc_svm, \"% accuracy with\", err_svm, \"% error\\n(estimated with\", len(results_svm), \"fold cross validation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd1da9-d8f5-4d98-ad0f-bb730370e11b",
   "metadata": {},
   "source": [
    "#### k Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34522b7c-f74b-4f9e-a45d-c0af3eee8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "results_knn = cross_val_score(clf_knn, data, y, cv=len(results_major))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "afbbe680-ebb6-4966-820e-b6b324d3f096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN has 40.739 % accuracy with 1.165 % error\n",
      "(estimated with 10 fold cross validation)\n"
     ]
    }
   ],
   "source": [
    "acc_knn = np.round(np.mean(results_knn) * 100, decimals=3)\n",
    "err_knn = np.round(np.std(results_knn) * 100, decimals=3)\n",
    "print(\"kNN has\", acc_knn, \"% accuracy with\", err_knn, \"% error\\n(estimated with\", len(results_knn), \"fold cross validation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742bf4b-25c7-4c56-8ffe-1077f14bfb15",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8fab85d6-3b0f-4717-b1b7-d14f08c4ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()\n",
    "results_rf = cross_val_score(clf_rf, data, y, cv=len(results_major))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18dbe9b1-790c-4e5c-9419-88b113047938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF has 76.311 % accuracy with 0.702 % error\n",
      "(estimated with 10 fold cross validation)\n"
     ]
    }
   ],
   "source": [
    "acc_rf = np.round(np.mean(results_rf) * 100, decimals=3)\n",
    "err_rf = np.round(np.std(results_rf) * 100, decimals=3)\n",
    "print(\"RF has\", acc_rf, \"% accuracy with\", err_rf, \"% error\\n(estimated with\", len(results_rf), \"fold cross validation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b912e2e7-a0c1-4878-a321-fdec2491e616",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "481ea36c-b68f-4181-ba31-228cab75683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS - PART 2\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import normalize, relu\n",
    "\n",
    "from constants import path_to_bin, path_to_pssmP, path_ID, aa_order\n",
    "from feature_extraction import append_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2711bb88-bd4f-4be8-884d-476a535c3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE DATASET - consists of binary representation of AA sequence (N x 20)\n",
    "#                  and PSSM matrix (N x 20)\n",
    "class Enzymes(Dataset):\n",
    "    def __init__(self, bin_path, pssm_path, data, names, transform):\n",
    "        super().__init__()\n",
    "        self.bin_path = bin_path\n",
    "        self.pssm_path = pssm_path\n",
    "        self.data = data\n",
    "        self.names = self.data.index\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        bin_name = os.path.join(self.bin_path, names[idx])\n",
    "        pssm_name = os.path.join(self.pssm_path, names[idx])\n",
    "        bin_im = np.loadtxt(bin_name)\n",
    "        pssm_im = np.loadtxt(pssm_name)\n",
    "        feat = self.data.loc[names[idx].split('.')[0], :].to_numpy()\n",
    "        sample = {'bin': bin_im, 'pssm': pssm_im, 'feat':feat}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ced19a6e-445b-4d69-8c7b-884238562a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE TRANSFORMATION - such that binary and PSSM will act as color channels\n",
    "class ToTensors():\n",
    "    \n",
    "    def shuffle(self, x):\n",
    "        return x[:, aa_order]\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        bin_im, pssm_im = sample['bin'], sample['pssm']\n",
    "        bin_im = self.shuffle(bin_im).transpose((1, 0))\n",
    "        pssm_im = self.shuffle(pssm_im).transpose((1, 0))\n",
    "        return {'bin': torch.tensor([bin_im], dtype=torch.float32),\n",
    "               'pssm': torch.tensor([pssm_im], dtype=torch.float32),\n",
    "               'feat': torch.tensor(sample['feat'], dtype=torch.float32)}\n",
    "        \n",
    "        return {'bin': normalize(torch.tensor([bin_im], dtype=torch.float32)),\n",
    "               'pssm': normalize(torch.tensor([pssm_im], dtype=torch.float32))}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7bb803c1-9ecd-4762-81fe-945049b08988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ FILE WITH FILE NAMES (enzyme ID codes)\n",
    "with open(path_ID) as handle:\n",
    "    names = [name.strip() for name in handle.readlines() if name.split('.')[0] in data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "de0671c2-9401-4fee-bd17-38faf68f7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATASET\n",
    "data_cnn = Enzymes(path_to_bin, path_to_pssmP, data, names, transform=ToTensors())\n",
    "data_cnn = DataLoader(data_cnn, num_workers=4)\n",
    "\n",
    "# GROUND TRUTH\n",
    "labels = pd.get_dummies(append_truths(pd.DataFrame(index=[name.split('.')[0] for name in names]))).to_numpy()\n",
    "\n",
    "folds = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "79cbbd35-c48d-4054-99e9-97fd5ce18ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE NEURAL NETWORK\n",
    "class Neural(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 2)\n",
    "        self.conv3 = nn.Conv2d(1, 32, 2)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 2)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(3, 2)\n",
    "        self.full_con1 = nn.Linear(1536, 256)\n",
    "        self.full_con2 = nn.Linear(1536, 256)\n",
    "        self.full_con3 = nn.Linear(763, 256)\n",
    "        self.full_con4 = nn.Linear(256, 128)\n",
    "        self.full_con5 = nn.Linear(256, 128)\n",
    "        self.full_con6 = nn.Linear(256, 128)\n",
    "        self.full_last = nn.Linear(384, 7)\n",
    "        \n",
    "    def extract_bin(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x, h = nn.LSTM(x.size()[-1], 8, 2)(x)\n",
    "        x = torch.flatten(x, 0)\n",
    "        x = relu(self.full_con1(x))\n",
    "        x = relu(self.full_con4(x))\n",
    "        return x\n",
    "    \n",
    "    def extract_pssm(self, x):\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x, h = nn.LSTM(x.size()[-1], 8, 2)(x)\n",
    "        x = torch.flatten(x, 0)\n",
    "        x = relu(self.full_con2(x))\n",
    "        x = relu(self.full_con5(x))\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.extract_bin(x['bin'])\n",
    "        x2 = self.extract_pssm(x['pssm'])\n",
    "        x3 = self.full_con3(x['feat'])\n",
    "        x3 = relu(self.full_con6(x3))\n",
    "        x = torch.cat((x1, x2, x3))\n",
    "        x = self.full_last(x)\n",
    "        return x\n",
    "net = Neural()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "10bb4696-e7f5-466e-8d8f-7d07aa476043",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01, weight_decay=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "46d2d4ab-a059-47aa-bb4d-14d7a24b90b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.910\n",
      "[1,  4000] loss: 1.918\n",
      "[1,  6000] loss: 1.909\n",
      "[1,  8000] loss: 1.907\n",
      "[1, 10000] loss: 1.905\n",
      "[1, 12000] loss: 1.917\n",
      "[1, 14000] loss: 1.922\n",
      "[1, 16000] loss: 1.921\n",
      "[1, 18000] loss: 1.921\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(zip(data_cnn.dataset, labels)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, label = data\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        net.zero_grad(set_to_none=True)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, torch.tensor(label, dtype=torch.float32))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i > 18000:\n",
    "            break\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95b6275c-3025-442e-9d60-730aab1e5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c84b33ab-2185-4f7c-aa5e-c91fd13023a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './model_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2fa98989-c412-4a64-9c1f-c0ce7462c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i, x in enumerate(data_cnn.dataset):\n",
    "    if i < 18001:\n",
    "        continue\n",
    "    res.append(np.argmax(softmax(net(x).detach().numpy()))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9edcea35-d189-4e93-aafb-682e491518c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.02\n"
     ]
    }
   ],
   "source": [
    "true = np.argmax(labels[18001:], axis=1) + 1\n",
    "b = pd.Series(true, index=names[18001:]) == pd.Series(res, index=names[18001:])\n",
    "print(np.round(b.mean()*100, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7615c28-d76d-4e94-8c5d-5d84727b4caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
